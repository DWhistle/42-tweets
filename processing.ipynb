{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from collections import Counter\n",
    "from collections import namedtuple, defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sentiment = namedtuple('Sentiment', [\n",
    "    'type',\n",
    "    'ordinal',\n",
    "])\n",
    "\n",
    "Approach = namedtuple('Approach', [\n",
    "    'binary',\n",
    "    'counts',\n",
    "    'tfidf'\n",
    "])\n",
    "\n",
    "approaches = {\n",
    "    'tokenization': None,\n",
    "    'stemming': None,\n",
    "    'lemmatization': None,\n",
    "    's+m': None,\n",
    "    'l+m': None,\n",
    "}\n",
    "\n",
    "sentiments = {\n",
    "    'negative': Sentiment('negative', -1),\n",
    "    'positive': Sentiment('positive', 1),\n",
    "    'neutral': Sentiment('neutral', 0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser:\n",
    "    non_word_regex = re.compile(r\"[^0-9^A-Z^a-z^ ]\")\n",
    "    @classmethod\n",
    "    def filter_non_words(cls, text):\n",
    "        return Parser.non_word_regex.sub('', text).lower()\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse(path):\n",
    "        df = pd.read_csv(path)\n",
    "        df = pd.DataFrame(data={'col': df.items()}, index = range(df.shape[1]))\n",
    "        \n",
    "        return list(df['col'].apply(lambda r: Parser.filter_non_words(r[0])))\n",
    "\n",
    "    \n",
    "class Tokenizer:\n",
    "    ascii_word_regex = re.compile(r\"[0-9A-Za-z]+\")\n",
    "    \n",
    "    def __init__(self, tweets, sentiment):\n",
    "        self.tweets = tweets\n",
    "        self.sentiment = sentiments.get(sentiment)\n",
    "\n",
    "    def count_tokens(self, text):\n",
    "        words = Tokenizer.ascii_word_regex.findall(text)\n",
    "        wc = Counter(words)\n",
    "        wc['tweet'] = text\n",
    "        return dict(wc)\n",
    "\n",
    "    def format_to_row(self, wc):\n",
    "        wc['sentiment'] = self.sentiment.ordinal\n",
    "        return wc\n",
    "\n",
    "    def list_to_tokens(self):\n",
    "        wc = (self.count_tokens(text) for text in self.tweets)\n",
    "        final_rows = [self.format_to_row(wcount) for wcount in wc]\n",
    "        return final_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets = Tokenizer(Parser.parse('./data/processedNegative.csv'), 'negative').list_to_tokens() \\\n",
    "            + Tokenizer(Parser.parse('./data/processedPositive.csv'), 'positive').list_to_tokens() \\\n",
    "            + Tokenizer(Parser.parse('./data/processedNeutral.csv'), 'neutral').list_to_tokens()\n",
    "df = pd.DataFrame(all_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rearranging columns\n",
    "\n",
    "cols = list(df.columns)\n",
    "cols.remove('sentiment')\n",
    "cols.remove('tweet')\n",
    "df = df[['sentiment', 'tweet'] + cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling nans, slicing X, converting to ints\n",
    "df.fillna(0, inplace=True)\n",
    "processed_rows = df.iloc[:, 2:].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>how</th>\n",
       "      <th>unhappy</th>\n",
       "      <th>some</th>\n",
       "      <th>dogs</th>\n",
       "      <th>like</th>\n",
       "      <th>it</th>\n",
       "      <th>though</th>\n",
       "      <th>talking</th>\n",
       "      <th>to</th>\n",
       "      <th>my</th>\n",
       "      <th>...</th>\n",
       "      <th>limaye</th>\n",
       "      <th>diana</th>\n",
       "      <th>edulji</th>\n",
       "      <th>cag</th>\n",
       "      <th>4member</th>\n",
       "      <th>amulya</th>\n",
       "      <th>appointed</th>\n",
       "      <th>1985</th>\n",
       "      <th>agmut</th>\n",
       "      <th>cadre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3868</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3869</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3870</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3871</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3872</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3873 rows × 6780 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      how  unhappy  some  dogs  like  it  though  talking  to  my  ...  \\\n",
       "0       1        1     1     1     1   1       1        0   0   0  ...   \n",
       "1       0        0     0     0     0   0       0        1   3   1  ...   \n",
       "2       0        1     1     0     0   1       0        0   2   0  ...   \n",
       "3       0        1     0     0     0   0       0        0   1   0  ...   \n",
       "4       0        1     0     0     0   0       0        0   0   0  ...   \n",
       "...   ...      ...   ...   ...   ...  ..     ...      ...  ..  ..  ...   \n",
       "3868    0        0     0     0     0   0       0        0   0   0  ...   \n",
       "3869    0        0     0     0     0   0       0        0   1   0  ...   \n",
       "3870    0        0     0     0     0   0       0        0   1   0  ...   \n",
       "3871    0        0     0     0     0   0       0        0   0   0  ...   \n",
       "3872    0        0     0     0     0   0       0        0   0   0  ...   \n",
       "\n",
       "      limaye  diana  edulji  cag  4member  amulya  appointed  1985  agmut  \\\n",
       "0          0      0       0    0        0       0          0     0      0   \n",
       "1          0      0       0    0        0       0          0     0      0   \n",
       "2          0      0       0    0        0       0          0     0      0   \n",
       "3          0      0       0    0        0       0          0     0      0   \n",
       "4          0      0       0    0        0       0          0     0      0   \n",
       "...      ...    ...     ...  ...      ...     ...        ...   ...    ...   \n",
       "3868       1      0       0    0        0       0          0     0      0   \n",
       "3869       0      1       1    0        0       0          0     0      0   \n",
       "3870       0      0       0    1        1       0          0     0      0   \n",
       "3871       0      0       0    0        0       0          0     0      0   \n",
       "3872       0      0       0    0        0       1          1     1      1   \n",
       "\n",
       "      cadre  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "...     ...  \n",
       "3868      0  \n",
       "3869      0  \n",
       "3870      0  \n",
       "3871      0  \n",
       "3872      1  \n",
       "\n",
       "[3873 rows x 6780 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# processed_rows.apply(lambda r: [v & 1 for v in r])\n",
    "processed_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"foo\">\n",
    "\n",
    "| approach | 0 or 1, if the word exists | word counts | TFIDF |\n",
    "| --- | --- | --- | --- |\n",
    "| Just tokenization |  | |  |\n",
    "| Stemming |  | |  |\n",
    "| Lemmatization |  | |  |\n",
    "| Stemming + Misspellings |  | |  |\n",
    "| Lemmatization + Misspellings |  | |  |\n",
    "| Any other ... |  | |  |\n",
    "\n",
    "\n",
    " \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(processed_rows):\n",
    "    return processed_rows.apply(lambda r: [v & 1 for v in r])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFIDFProcessor:\n",
    "    def __init__(self, rows: pd.DataFrame):\n",
    "        self.rows = rows.copy()\n",
    "        self.num_of_texts = rows.shape[0]\n",
    "        self.num_of_apparitions = dict(TFIDFProcessor.binarize(rows).sum())\n",
    "    \n",
    "    @staticmethod\n",
    "    def binarize(rows):\n",
    "        return rows.apply(lambda r: [v & 1 for v in r])\n",
    "\n",
    "    def compute_tf(self):\n",
    "        return self.rows.apply(lambda r: r / sum(r), axis = 1)\n",
    "    \n",
    "    def compute_idf(self):\n",
    "        term_importances = {}\n",
    "        for w, c in self.num_of_apparitions.items():\n",
    "            num_of_occs = 1.0 if c <= 0 else float(c)\n",
    "            term_importances[w] = math.log10(float(self.num_of_texts) / num_of_occs)\n",
    "        return term_importances\n",
    "    \n",
    "    def compute_tfidf(self):\n",
    "        tf_dataset = self.compute_tf()\n",
    "        for word, importance in self.compute_idf().items():\n",
    "            tf_dataset[word] *= importance\n",
    "        return tf_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approaches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just tokenization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TFIDFProcessor(processed_rows)\n",
    "approaches['tokenization'] = Approach(binarize(processed_rows), processed_rows, tfidf.compute_tfidf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TFIDFProcessor(processed_rows)\n",
    "approaches['tokenization'] = Approach(binarize(processed_rows), processed_rows, tfidf.compute_tfidf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TFIDFProcessor(processed_rows)\n",
    "approaches['tokenization'] = Approach(binarize(processed_rows), processed_rows, tfidf.compute_tfidf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming + Lemmatization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TFIDFProcessor(processed_rows)\n",
    "approaches['tokenization'] = Approach(binarize(processed_rows), processed_rows, tfidf.compute_tfidf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization + misspellings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TFIDFProcessor(processed_rows)\n",
    "approaches['tokenization'] = Approach(binarize(processed_rows), processed_rows, tfidf.compute_tfidf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
